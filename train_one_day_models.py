# --- train_one_day_models.py ---
# This script trains ALL 6 models for ALL 5 stocks based on 8 FEATURES (OHLCV + TA).
# These models are for the accurate 1-day-ahead forecast.
# It saves them to the 'stock_models/one_day/' subdirectory.
# (Version 2: Fixed scaler transformation error in regressor loop)

import yfinance as yf
import numpy as np
import pandas as pd
import os
import joblib
import warnings
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from xgboost import XGBRegressor

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from datetime import datetime

# --- 0. Setup ---
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TensorFlow warnings

# Create the subdirectory for these new models
MODELS_DIR = 'stock_models/one_day'
if not os.path.exists(MODELS_DIR):
    os.makedirs(MODELS_DIR, exist_ok=True)
    print(f"Created directory: {MODELS_DIR}")

STOCK_LIST = {
    'Infosys': 'INFY.NS',
    'Yes Bank': 'YESBANK.NS',
    'TCS': 'TCS.NS',
    'HDFC Bank': 'HDFCBANK.NS',
    'ITC': 'ITC.NS'
}
TIME_STEP = 100 # Use 100 days of history
START_DATE = '2015-01-01' # Use 10+ years of data

# Define the features we will use for training
FEATURE_COLUMNS = ['Open', 'High', 'Low', 'Close', 'Volume', 'SMA_50', 'RSI_14']
TARGET_COLUMN = 'Close' # We are predicting the 'Close' price

# --- 1. Function to Fetch Data and Add Features (Manual TA) ---
def fetch_and_prepare_data(ticker, start_date='2015-01-01'):
    end_date = datetime.now().strftime('%Y-%m-%d')
    print(f"Fetching data for {ticker} from {start_date} to {end_date}...")
    
    data = yf.download(ticker, start=start_date, end=end_date)
    
    if data.empty:
        print(f"No data found for ticker {ticker}.")
        return None
    
    # --- Manual Technical Indicators ---
    
    # 1. Simple Moving Average (SMA)
    data['SMA_50'] = data['Close'].rolling(window=50).mean()
    
    # 2. Relative Strength Index (RSI)
    delta = data['Close'].diff(1)
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    # Use exponential moving average for RSI calculation
    avg_gain = gain.ewm(com=14 - 1, min_periods=14).mean()
    avg_loss = loss.ewm(com=14 - 1, min_periods=14).mean()
    rs = avg_gain / avg_loss
    data['RSI_14'] = 100 - (100 / (1 + rs))
    
    # Drop rows with NaN values (generated by TA indicators)
    data.dropna(inplace=True)
    
    print(f"Data fetched and features added for {ticker}")
    return data

# --- 3. Function to Train the LSTM Model ---
def train_and_save_lstm(ticker, data):
    print(f"\n--- Training LSTM for {ticker} ---")
    try:
        # A. Isolate features and target
        features_df = data[FEATURE_COLUMNS]
        target_df = data[[TARGET_COLUMN]]

        # B. Create and save scalers
        scaler_X = MinMaxScaler(feature_range=(0, 1))
        scaler_y = MinMaxScaler(feature_range=(0, 1))
        
        scaled_X = scaler_X.fit_transform(features_df)
        scaled_y = scaler_y.fit_transform(target_df)
        
        joblib.dump(scaler_X, os.path.join(MODELS_DIR, f"{ticker}_X_scaler.joblib"))
        joblib.dump(scaler_y, os.path.join(MODELS_DIR, f"{ticker}_y_scaler.joblib"))
        print(f"Scalers for {ticker} saved to {MODELS_DIR}")

        # C. Create sequences from scaled data
        X_seq, y_seq = [], []
        for i in range(TIME_STEP, len(scaled_X)):
            X_seq.append(scaled_X[i-TIME_STEP:i, :]) # All feature columns
            y_seq.append(scaled_y[i, 0]) # The target column
            
        X_train, y_train = np.array(X_seq), np.array(y_seq)

        # D. Build Model (Input shape now has multiple features)
        n_features = X_train.shape[2]
        model = Sequential()
        model.add(LSTM(units=50, return_sequences=True, input_shape=(TIME_STEP, n_features)))
        model.add(Dropout(0.2))
        model.add(LSTM(units=50, return_sequences=False))
        model.add(Dropout(0.2))
        model.add(Dense(units=25))
        model.add(Dropout(0.2))
        model.add(Dense(units=1))
        
        model.compile(optimizer='adam', loss='mean_squared_error')
        
        # E. Train Model
        print(f"Training LSTM for {ticker}...")
        model.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1)
        
        # F. Save Model
        model.save(os.path.join(MODELS_DIR, f"{ticker}_LSTM.h5"))
        print(f"LSTM Model for {ticker} saved to {MODELS_DIR}")
        
    except Exception as e:
        print(f"Error training LSTM for {ticker}: {e}")
        import traceback
        traceback.print_exc()

# --- 4. Function to Train ALL Regressor Models (DEBUGGED) ---
def train_and_save_regressors(ticker, data):
    print(f"\n--- Training Regressors for {ticker} ---")
    
    # A. Load scalers
    try:
        scaler_X = joblib.load(os.path.join(MODELS_DIR, f"{ticker}_X_scaler.joblib"))
        scaler_y = joblib.load(os.path.join(MODELS_DIR, f"{ticker}_y_scaler.joblib"))
    except FileNotFoundError:
        print(f"Scalers not found for {ticker}. Run LSTM training first.")
        return

    # B. Isolate and scale feature and target data IN BULK
    features_df = data[FEATURE_COLUMNS]
    target_df = data[[TARGET_COLUMN]] # Keep as DataFrame (2D)
    
    scaled_X = scaler_X.transform(features_df) # (samples, 8)
    scaled_y = scaler_y.transform(target_df) # (samples, 1)

    # C. Create sequences (This time, we flatten the features)
    X, y = [], []
    for i in range(TIME_STEP, len(scaled_X)):
        # Get the scaled feature rows and flatten
        scaled_feature_slice = scaled_X[i-TIME_STEP:i, :]
        X.append(scaled_feature_slice.flatten()) # Flatten (100, 8) to (800,)
        
        # Get the corresponding scaled target
        y.append(scaled_y[i, 0])
            
    X, y = np.array(X), np.array(y)
    
    if X.shape[0] == 0:
        print(f"Not enough data to train regressors for {ticker}.")
        return

    # D. Define the models to train
    models_to_train = {
        "LinearRegression": LinearRegression(),
        "DecisionTree": DecisionTreeRegressor(random_state=42),
        "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
        "SVR": SVR(kernel='rbf', C=1.0, epsilon=0.1),
        "XGBoost": XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42, n_jobs=-1)
    }
    
    # E. Train and Save each model
    for name, model in models_to_train.items():
        try:
            print(f"Training {name} for {ticker}...")
            model.fit(X, y)
            
            # Save the trained model
            model_path = os.path.join(MODELS_DIR, f"{ticker}_{name}.joblib")
            joblib.dump(model, model_path)
            print(f"Saved {name} for {ticker} to {MODELS_DIR}")
            
        except Exception as e:
            print(f"Error training {name} for {ticker}: {e}")

# --- 5. Main Execution Loop ---
if __name__ == "__main__":
    print(f"Starting 1-day-ahead model training pipeline...")
    print(f"Models will be saved in: {MODELS_DIR}")
    
    for stock_name, ticker_symbol in STOCK_LIST.items():
        print(f"\n=========================================")
        print(f"Processing: {stock_name} ({ticker_symbol})")
        print(f"=========================================")
        
        # 1. Fetch and prepare data with features
        full_data = fetch_and_prepare_data(ticker_symbol, START_DATE)
        
        if full_data is None:
            continue
            
        # 2. Train and save the LSTM (and the scalers)
        # We train LSTM first to create and save the scalers
        train_and_save_lstm(ticker_symbol, full_data)
        
        # 3. Train and save all 5 regressor models (using the same scalers)
        train_and_save_regressors(ticker_symbol, full_data)

    print(f"\n\n--- ALL 1-DAY-AHEAD MODELS HAVE BEEN TRAINED AND SAVED! ---")